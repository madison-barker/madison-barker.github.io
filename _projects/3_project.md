---
layout: page
title: Event Descriptions
description: Describing photographs of events
img: assets/img/mongolia.jpg
importance: 3
category: work
---

Much of what is known about language production stems from research using highly controlled, often artificial tasks such as picture naming or single sentence descriptions. While these paradigms offer strong experimental control (i.e., we can easily manipulate the variables of interest), they lack the ecological validity of natural discourse and real-world visual complexity. 

Consequently, our understanding of how speakers plan and produce multi-utterance, extemporaneous language in response to naturalistic stimuli, especially static images that imply dynamic content, remains limited. This project introduces a methodological approach that leverages visually rich, naturalistic images to elicit more ecologically valid language data.

Unlike objects, events are not directly observable in static scenes; they must be inferred through the relations among entities. Moreover, the way speakers choose to describe a visual environment is often dictated by properties of the environment itself (e.g., entities or events). To investigate how people produce discourse in complex environments, we developed a methodological framework that leverages photorealistic, semantically rich static scenes depicting one or more implied motion events. 

This project provides a scalable and generalizable approach for identifying, localizing, and quantifying events in still images offering a foundation for examining how speakers apprehend, prioritize, and describe dynamic content from visual input.

**Project Tools:** Open-Ended Verbal Data Collection - Survey (**Qualtrics**), Spatial Data Collection (**Qualtrics**), Verbal Data Collection (**Spoken**), Eyetracking (**Eyelink 1000+**); WhisperAI, MATLAB, Python, R, mixed-effects modeling, NLP, unsupervised learning, Adobe, MS Excel. 


<!-- To give your project a background in the portfolio page, just add the img tag to the front matter like so:

    ---
    layout: page
    title: project
    description: a project with a background image
    img: /assets/img/12.jpg
    --- -->

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/mongolia.jpg" title="example event scene - outdoor" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/reading_writing.jpg" title="example event scene - indoor" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Here are two examples of event scenes that participants described while their eye movements were recorded. Participants described 30 scenes for 30 seconds. Each subject described 15 scenes that depicted indoor environments and 15 scenes that depicted outdoor environments. 
</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure class="text-center">
            {% include figure.liquid loading="eager" path="assets/img/reading_writing.png" title="example event scene - outdoor" class="img-fluid rounded z-depth-1" %}
            <figcaption> (a) Event Map</figcaption>
        </figure>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure class="text-center">
            {% include figure.liquid loading="eager" path="assets/img/reading_writing_meaning.png" title="example event scene - indoor" class="img-fluid rounded z-depth-1" %}
            <figcaption> (b) Meaning Map</figcaption>
        </figure>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure class="text-center">
            {% include figure.liquid loading="eager" path="assets/img/reading_writing_interact.png" title="example event scene - indoor" class="img-fluid rounded z-depth-1" %}
            <figcaption> (c) Interactability Map</figcaption>
        </figure>
    </div>
</div>
<div class="caption">
    Here is an example of an event map (a), and semantic feature maps: the spatial distribution of meaning (b), and the spatial distribution of interactability (c) (i.e., how interactable areas of a scene are perceived to be).
</div>
